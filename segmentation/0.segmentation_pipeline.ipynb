{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bin2cell\n",
    "import json\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import bin2cell as b2c\n",
    "from pathlib import Path\n",
    "import scanpy as sc \n",
    "import matplotlib.pyplot as plt\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "IMMUNEXID = \"IMMUNEX001\"\n",
    "config_name = \"standard_LowHE_LowGEX\"\n",
    "mpp = 0.2\n",
    "\n",
    "he_stardist_params = {\n",
    "    \"stardist_model\": \"2D_versatile_he\",\n",
    "    \"prob_thresh\": 0.1,\n",
    "    'block_size':256,         # ✅ Small block size\n",
    "    \"min_overlap\": 64,     # smaller than smallest cell\n",
    "    \"context\": 16         # must still satisfy: min_overlap + 2×context < block_size\n",
    "}\n",
    "\n",
    "gex_stardist_params = {\n",
    "    \"image_path\": \"stardist/gex.tiff\",\n",
    "    \"labels_npz_path\": \"stardist/gex.npz\",\n",
    "    \"stardist_model\": \"2D_versatile_fluo\",\n",
    "    \"prob_thresh\": 0.1,\n",
    "    \"nms_thresh\": 0.1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Patched image loader\n",
    "def patched_load_image(image_path, **kwargs):\n",
    "    if not isinstance(image_path, (str, Path)):\n",
    "        raise ValueError(f\"Expected a path, got {type(image_path)} instead.\")\n",
    "    print(f\"Loading image via tifffile: {image_path}\")\n",
    "    img = tifffile.imread(image_path)\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "    elif img.shape[0] == 3 and img.ndim == 3:\n",
    "        img = np.moveaxis(img, 0, -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import napari\n",
    "\n",
    "def napari_spots(adata, spot_size=1, colormap='viridis', spot_layers=None, image_layers=None):\n",
    "    \"\"\"\n",
    "    Launch Napari with one or more image layers and spot layers from adata.\n",
    "\n",
    "    Parameters:\n",
    "    - adata: AnnData object\n",
    "    - spot_size: float, size of each spot\n",
    "    - colormap: str, colormap for numeric features\n",
    "    - spot_layers: list of adata.obs column names to plot as separate point layers\n",
    "    - image_layers: list of image sources to include, e.g. ['hires', 'spatial_cropped_150_buffer']\n",
    "        - 'hires' refers to adata.uns['spatial'][sample_key]['images']['hires']\n",
    "        - anything else looks in adata.obsm\n",
    "    \"\"\"\n",
    "    if spot_layers is None:\n",
    "        spot_layers = []\n",
    "    if image_layers is None:\n",
    "        image_layers = ['hires']  # default to hires tissue image\n",
    "\n",
    "    sample_key = list(adata.uns['spatial'].keys())[0]\n",
    "    scale = adata.uns['spatial'][sample_key]['scalefactors']['tissue_hires_scalef']\n",
    "    coords = adata.obsm['spatial'] * scale\n",
    "    coords = coords[:, [1, 0]]\n",
    "\n",
    "    # Start viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # Add requested image layers\n",
    "    for img_key in image_layers:\n",
    "        if img_key == 'hires':\n",
    "            image = adata.uns['spatial'][sample_key]['images']['hires']\n",
    "            viewer.add_image(image, name='Tissue image (hires)')\n",
    "        elif img_key in adata.obsm:\n",
    "            image = adata.obsm[img_key]\n",
    "            if image.ndim == 2 or (image.ndim == 3 and image.shape[-1] in [1, 3]):\n",
    "                viewer.add_image(image, name=f'{img_key}')\n",
    "            else:\n",
    "                print(f\"[Warning] '{img_key}' in adata.obsm is not a valid 2D or RGB image. Skipping.\")\n",
    "        else:\n",
    "            print(f\"[Warning] Image key '{img_key}' not found in adata.uns or obsm. Skipping.\")\n",
    "\n",
    "    # Base UMI spot layer\n",
    "    umi_values = np.nan_to_num(adata.obs['n_counts'].values)\n",
    "    base_properties = {'UMI': umi_values}\n",
    "    base_layer = viewer.add_points(\n",
    "        coords,\n",
    "        properties=base_properties,\n",
    "        face_color='UMI',\n",
    "        face_colormap=colormap,\n",
    "        size=spot_size,\n",
    "        name='UMI-colored spots'\n",
    "    )\n",
    "\n",
    "    base_layer.border_width = 0\n",
    "    base_layer.face_color = 'UMI'\n",
    "    base_layer.face_color_mode = 'colormap'\n",
    "    # base_layer.face_color_mode = 'direct'\n",
    "    \n",
    "    base_layer.face_contrast_limits = (umi_values.min(), umi_values.max())\n",
    "    base_layer.show_colorbar = True\n",
    "\n",
    "    print(\"Layer properties keys:\", base_layer.properties.keys())\n",
    "    print(\"Layer properties values:\", base_layer.properties.values())\n",
    "    print(\"Face color mode:\", base_layer.face_color_mode)\n",
    "    print(\"Face color source:\", base_layer.face_color)\n",
    "    \n",
    "    # Additional spot layers\n",
    "    for layer_name in spot_layers:\n",
    "        if layer_name in adata.obs.columns:\n",
    "            values = np.nan_to_num(adata.obs[layer_name].values)\n",
    "            properties = {layer_name: values}\n",
    "            layer = viewer.add_points(\n",
    "                coords,\n",
    "                properties=properties,\n",
    "                face_color=layer_name,\n",
    "                face_colormap=colormap,\n",
    "                size=spot_size,\n",
    "                name=f'{layer_name} layer'\n",
    "            )\n",
    "            layer.face_color_mode = 'colormap'\n",
    "            layer.face_contrast_limits = (values.min(), values.max())\n",
    "            layer.border_width = 0\n",
    "            layer.show_colorbar = True\n",
    "\n",
    "        else:\n",
    "            print(f\"[Warning] '{layer_name}' not found in adata.obs. Skipping.\")\n",
    "\n",
    "    print(\"Napari viewer created.\")\n",
    "    return viewer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_sample_path = Path(f\"/Users/mounim/Documents/IMMUNEX_data/\") # spaceranger output folder \n",
    "sample_folder = base_sample_path / f\"OUTPUT/spaceranger_output//Visium_NSCLC_{IMMUNEXID}\"\n",
    "path_visium = f'{sample_folder}/outs/binned_outputs/square_002um/'\n",
    "\n",
    "# Load suffix mapping\n",
    "with open(\"../data/metadata/he_mapping_suffix.json\", \"r\") as f:\n",
    "    nanozoomer_tif = json.load(f)\n",
    "source_image_path = Path(f\"{base_sample_path}/IMAGE/IMAGE/HE_nanozoomer_tif/\") / f\"{IMMUNEXID}{nanozoomer_tif[IMMUNEXID]}.tif\"\n",
    "\n",
    "path_spaceranger = Path(base_sample_path / f\"OUTPUT/spaceranger_output//Visium_NSCLC_{IMMUNEXID}/outs/spatial\")\n",
    "\n",
    "# Output paths\n",
    "\n",
    "# Paths\n",
    "base_output_dir = Path(f\"./data/intermediate/segmentation/bin2cell/{IMMUNEXID}/\")\n",
    "output_dir = base_output_dir / f\"{IMMUNEXID}__{config_name}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inspect file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "anndata.py (1758): Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "anndata.py (1758): Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 10822530 × 18536\n",
      "    obs: 'in_tissue', 'array_row', 'array_col'\n",
      "    var: 'gene_ids', 'feature_types', 'genome'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n",
      "n counted\n",
      "filtred\n",
      "AnnData object with n_obs × n_vars = 10822530 × 18536\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'n_counts'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n"
     ]
    }
   ],
   "source": [
    "# Start processing\n",
    "adata = b2c.read_visium(\n",
    "    path= path_visium, \n",
    "    count_file='./filtered_feature_bc_matrix.h5',\n",
    "    source_image_path= source_image_path,\n",
    "    spaceranger_image_path= path_spaceranger\n",
    ")\n",
    "adata.var_names_make_unique()\n",
    "print(adata)\n",
    "\n",
    "adata.obs['n_counts'] = np.sum(adata.X, axis=1).A1 if hasattr(adata.X, 'A1') else np.sum(adata.X, axis=1)\n",
    "print('n counted')\n",
    "sc.pp.filter_genes(adata, min_cells=0)\n",
    "sc.pp.filter_cells(adata, min_counts=0)\n",
    "print('filtred')\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# napari_spots(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_construct.py (163): Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata destripped AnnData object with n_obs × n_vars = 10822530 × 18536\n",
      "    obs: 'in_tissue', 'array_row', 'array_col', 'n_counts', 'destripe_factor', 'n_counts_adjusted'\n",
      "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
      "    uns: 'spatial'\n",
      "    obsm: 'spatial'\n"
     ]
    }
   ],
   "source": [
    "b2c.bin2cell.load_image = patched_load_image\n",
    "\n",
    "# # Destripe and scale image\n",
    "b2c.destripe(adata)\n",
    "print('adata destripped', adata)\n",
    "he_img_out = output_dir / \"he.tiff\"\n",
    "\n",
    "# napari_spots(adata, spot_layers=['n_counts_adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image via tifffile: /Users/mounim/Documents/IMMUNEX_data/IMAGE/IMAGE/HE_nanozoomer_tif/IMMUNEX001_Visium_HE_x40_z0.tif\n",
      "Cropped spatial coordinates key: spatial_cropped_150_buffer\n",
      "Image key: 0.2_mpp_150_buffer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10822530 × 18536\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_counts', 'destripe_factor', 'n_counts_adjusted'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
       "    uns: 'spatial'\n",
       "    obsm: 'spatial', 'spatial_cropped_150_buffer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2c.bin2cell.load_image = patched_load_image\n",
    "\n",
    "b2c.scaled_he_image(\n",
    "    adata,\n",
    "    save_path=he_img_out, \n",
    "    mpp=mpp\n",
    "    )\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer properties keys: dict_keys(['UMI'])\n",
      "Layer properties values: dict_values([array([ 0., 16.,  5., ...,  0.,  3.,  1.], dtype=float32)])\n",
      "Face color mode: ColorMode.COLORMAP\n",
      "Face color source: [[0.26700401 0.004874   0.32941499 1.        ]\n",
      " [0.2832185  0.12204475 0.441678   1.        ]\n",
      " [0.27563746 0.04186161 0.36814395 1.        ]\n",
      " ...\n",
      " [0.26700401 0.004874   0.32941499 1.        ]\n",
      " [0.27257386 0.02547517 0.353002   1.        ]\n",
      " [0.26898054 0.01125219 0.33737999 1.        ]]\n",
      "Napari viewer created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Viewer(camera=Camera(center=(0.0, 2315.5, 2999.5), zoom=0.0931, angles=(0.0, 0.0, 90.0), perspective=0.0, mouse_pan=True, mouse_zoom=True, orientation=(<DepthAxisOrientation.TOWARDS: 'towards'>, <VerticalAxisOrientation.DOWN: 'down'>, <HorizontalAxisOrientation.RIGHT: 'right'>)), cursor=Cursor(position=(1.0, 1.0), scaled=True, style=<CursorStyle.STANDARD: 'standard'>, size=1.0), dims=Dims(ndim=2, ndisplay=2, order=(0, 1), axis_labels=('0', '1'), rollable=(True, True), range=(RangeTuple(start=0.0, stop=4631.0, step=1.0), RangeTuple(start=0.0, stop=5999.0, step=1.0)), margin_left=(0.0, 0.0), margin_right=(0.0, 0.0), point=(2315.0, 2999.0), last_used=0), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False, spacing=0.0), layers=[<Image layer 'Tissue image (hires)' at 0x559ec4490>, <Points layer 'UMI-colored spots' at 0x559e4a230>, <Points layer 'n_counts_adjusted layer' at 0x55bb35210>], help='use <5> for transform, use <2> for add points, use <3> for select points', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[], mouse_drag_callbacks=[], mouse_double_click_callbacks=[<function double_click_to_zoom at 0x349bd6a70>], mouse_wheel_callbacks=[<function dims_scroll at 0x349bd60e0>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, _keymap={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari_spots(adata, spot_layers=['n_counts_adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# sc.set_figure_params(figsize=[5, 5], dpi=100)\n",
    "\n",
    "# # Use explicit keys and object\n",
    "# sc.pl.spatial(\n",
    "#     adata,\n",
    "#     color=[None, \"n_counts\", \"n_counts_adjusted\"],\n",
    "#     img_key=f\"{mpp}_mpp_150_buffer\",\n",
    "#     basis=\"spatial_cropped_150_buffer\",\n",
    "#     cmap='Reds',\n",
    "#     show=False\n",
    "# )\n",
    "# plt.savefig(output_dir / \"spatial_destriping.pdf\")\n",
    "# plt.close()\n",
    "\n",
    "# print('HE preview exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34177, 34175, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key = list(adata.uns['spatial'].keys())[0]\n",
    "adata.uns['spatial'][sample_key]['images']['0.2_mpp_150_buffer'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stardist.models import StarDist2D\n",
    "import napari\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_he')\n",
    "\n",
    "# Extract a crop from adata\n",
    "sample_key = list(adata.uns['spatial'].keys())[0]\n",
    "crop = adata.uns['spatial'][sample_key]['images']['0.2_mpp_150_buffer'][1000:10000, 1000:10000]\n",
    "\n",
    "# tifffile.imwrite(\"HE_image.tif\", crop = adata.uns['spatial'][sample_key]['images']['0.2_mpp_150_buffer'])\n",
    "tifffile.imwrite(\"crop_HE_image.tif\", crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting with prob_thresh=0.1, nms_thresh=0.3, block=(1000, 1000, 1)\n",
      "effective: block_size=(1008, 1008, 3), min_overlap=(112, 112, 0), context=(32, 32, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "functional.py (238): The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, 256, 256, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: context of 32 is small, recommended to use at least 94\n",
      "X: context of 32 is small, recommended to use at least 94\n",
      "changing 'show_tile_progress' from False to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base.py (406): Predicting on non-float input... ( forgot to normalize? )\n",
      "functional.py (238): The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, 1008, 1008, 3))\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.08it/s]\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Cells identified: 41\n",
      "Segmenting with prob_thresh=0.5, nms_thresh=0.3, block=(1000, 1000, 1)\n",
      "effective: block_size=(1008, 1008, 3), min_overlap=(112, 112, 0), context=(32, 32, 0)\n",
      "Y: context of 32 is small, recommended to use at least 94\n",
      "X: context of 32 is small, recommended to use at least 94\n",
      "changing 'show_tile_progress' from False to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base.py (406): Predicting on non-float input... ( forgot to normalize? )\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.39it/s]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Cells identified: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from stardist.models import StarDist2D\n",
    "import napari\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "# Save and reload crop (if needed)\n",
    "crop = tifffile.imread(\"crop_HE_image.tif\")\n",
    "\n",
    "# Set up Napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(crop, name='Original H&E Image')\n",
    "\n",
    "# Load model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_he')\n",
    "\n",
    "# Parameters to test\n",
    "prob_values = [0.1, 0.5]\n",
    "params = [\n",
    "    {'block_size': (1000, 1000, 1), 'min_overlap': (100, 100, 0), 'context': (25, 25, 0)},\n",
    "]\n",
    "\n",
    "# Color list (adjust length if needed)\n",
    "color_list = ['red', 'green', 'blue', 'yellow', 'cyan', 'magenta']\n",
    "\n",
    "# Loop\n",
    "color_index = 0\n",
    "for p in tqdm(prob_values):\n",
    "    for nms in [0.3]:\n",
    "        for param in params:\n",
    "            print(f\"Segmenting with prob_thresh={p}, nms_thresh={nms}, block={param['block_size']}\")\n",
    "\n",
    "            labels, _ = model.predict_instances_big(\n",
    "                crop,\n",
    "                axes='YXC',\n",
    "                prob_thresh=p,\n",
    "                nms_thresh=nms,\n",
    "                block_size=param['block_size'],\n",
    "                min_overlap=param['min_overlap'],\n",
    "                context=param['context'],\n",
    "                verbose=False,\n",
    "                show_tile_progress=False\n",
    "            )\n",
    "\n",
    "            layer_name = f\"p={p:.2f} | block={param['block_size'][0]}\"\n",
    "            layer = viewer.add_labels(labels, name=layer_name)\n",
    "            layer.opacity = 0.5\n",
    "            layer.rendering = 'translucent'\n",
    "            print(f\" → Cells identified: {np.max(labels)}\")\n",
    "\n",
    "            color_index += 1\n",
    "\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (34177, 34175, 3)\n",
      "Loading image via tifffile: data/intermediate/segmentation/bin2cell/IMMUNEX001/IMMUNEX001__standard_LowHE_LowGEX/he.tiff\n",
      "Found model '2D_versatile_he' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.692478, nms_thresh=0.3.\n",
      "effective: block_size=(256, 256, 3), min_overlap=(96, 96, 0), context=(16, 16, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "functional.py (238): The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, 256, 256, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: context of 16 is small, recommended to use at least 94\n",
      "X: context of 16 is small, recommended to use at least 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 666/71022 [01:00<1:47:05, 10.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m he_seg_out \u001b[38;5;241m=\u001b[39m output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhe.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# # H&E segmentation\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mb2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstardist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhe_img_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_npz_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhe_seg_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhe_stardist_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStardist H&E done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable obsm keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, adata\u001b[38;5;241m.\u001b[39mobsm\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/bin2cell/bin2cell.py:136\u001b[0m, in \u001b[0;36mstardist\u001b[0;34m(image_path, labels_npz_path, stardist_model, block_size, min_overlap, context, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     model_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYX\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#run predict_instances_big() to perform automated tiling of the input\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#this is less parameterised than predict_instances, needed to pass axes too\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#pass any other **kwargs to the thing, passing them on internally\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#in practice this is going to be prob_thresh\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_instances_big\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmin_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#store resulting labels as sparse matrix NPZ - super efficient space wise\u001b[39;00m\n\u001b[1;32m    143\u001b[0m labels_sparse \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(labels)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/models/base.py:954\u001b[0m, in \u001b[0;36mStarDistBase.predict_instances_big\u001b[0;34m(self, img, axes, block_size, min_overlap, context, labels_out, labels_out_dtype, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# actual computation\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m blocks:\n\u001b[0;32m--> 954\u001b[0m     labels, polys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m     labels \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39mcrop_context(labels, axes\u001b[38;5;241m=\u001b[39maxes_out)\n\u001b[1;32m    956\u001b[0m     labels, polys \u001b[38;5;241m=\u001b[39m block\u001b[38;5;241m.\u001b[39mfilter_objects(labels, polys, axes\u001b[38;5;241m=\u001b[39maxes_out)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/models/base.py:788\u001b[0m, in \u001b[0;36mStarDistBase.predict_instances\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(_predict_instances_generator)\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_instances\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# the reason why the actual computation happens as a generator function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m \n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# return last \"yield\"ed value of generator\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_instances_generator(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/models/base.py:758\u001b[0m, in \u001b[0;36mStarDistBase._predict_instances_generator\u001b[0;34m(self, img, axes, normalizer, sparse, prob_thresh, nms_thresh, scale, n_tiles, show_tile_progress, verbose, return_labels, predict_kwargs, nms_kwargs, overlap_label, return_predict)\u001b[0m\n\u001b[1;32m    755\u001b[0m     prob_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnms\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# indicate that non-maximum suppression is starting\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m res_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instances_from_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_shape_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mprob_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprob_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mprob_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprob_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnms_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnms_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mreturn_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43moverlap_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverlap_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m                                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnms_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;66;03m# last \"yield\" is the actual output that would have been \"return\"ed if this was a regular function\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_predict:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/models/model2d.py:526\u001b[0m, in \u001b[0;36mStarDist2D._instances_from_prediction\u001b[0;34m(self, img_shape, prob, dist, points, prob_class, prob_thresh, nms_thresh, overlap_label, return_labels, scale, **nms_kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# sparse prediction\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     points, probi, disti, indsi \u001b[38;5;241m=\u001b[39m \u001b[43mnon_maximum_suppression_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnms_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnms_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m         prob_class \u001b[38;5;241m=\u001b[39m prob_class[indsi]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/nms.py:177\u001b[0m, in \u001b[0;36mnon_maximum_suppression_sparse\u001b[0;34m(dist, prob, points, b, nms_thresh, use_bbox, use_kdtree, verbose)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-maximum suppression...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m     t \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 177\u001b[0m inds \u001b[38;5;241m=\u001b[39m \u001b[43mnon_maximum_suppression_inds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpointsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnms_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_kdtree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_kdtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeeping \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m polyhedra\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mcount_nonzero(inds), \u001b[38;5;28mlen\u001b[39m(inds)))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages/stardist/nms.py:220\u001b[0m, in \u001b[0;36mnon_maximum_suppression_inds\u001b[0;34m(dist, points, scores, thresh, use_bbox, use_kdtree, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_prep\u001b[39m(x, dtype):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 220\u001b[0m inds \u001b[38;5;241m=\u001b[39m \u001b[43mc_non_max_suppression_inds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m_prep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muse_kdtree\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muse_bbox\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "he_stardist_params = {\n",
    "    \"stardist_model\": \"2D_versatile_he\",\n",
    "    \"prob_thresh\": 0.1,\n",
    "    \"block_size\": 256,\n",
    "    \"min_overlap\": 96,    # ↑ increase overlap\n",
    "    \"context\": 16         # keep this small enough to satisfy constraint\n",
    "}\n",
    "\n",
    "\n",
    "from tifffile import imread\n",
    "\n",
    "he_img_out = output_dir / \"he.tiff\"\n",
    "\n",
    "img = imread(he_img_out)\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "he_seg_out = output_dir / \"he.npz\"\n",
    "# # H&E segmentation\n",
    "b2c.stardist(\n",
    "    image_path=str(he_img_out),\n",
    "    labels_npz_path=str(he_seg_out), \n",
    "    **he_stardist_params)\n",
    "\n",
    "print(\"Stardist H&E done\")\n",
    "\n",
    "\n",
    "print(\"Available obsm keys:\", adata.obsm.keys())\n",
    "sample_id = list(adata.uns[\"spatial\"].keys())[0]\n",
    "print(\"Image keys:\", adata.uns[\"spatial\"][sample_id][\"images\"].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (80.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/bin2cell_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-macosx_12_0_arm64.whl (252.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl (11.3 MB)\n",
      "Downloading ml_dtypes-0.5.1-cp310-cp310-macosx_10_9_universal2.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.5/671.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-macosx_11_0_arm64.whl (329 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [tensorflow]0\u001b[0m [tensorflow]]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c.insert_labels(adata, str(he_seg_out), basis=\"spatial\", spatial_key=\"spatial_cropped_150_buffer\", mpp=mpp, labels_key=\"labels_he\")\n",
    "\n",
    "print(\"Inserted H&E labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c.expand_labels(\n",
    "    adata,\n",
    "    labels_key=\"labels_he\",\n",
    "    expanded_labels_key=\"labels_he_expanded\"\n",
    ")\n",
    "print(\"Expanded H&E labels\")\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the crop from the spatial coordinates\n",
    "crop = b2c.get_crop(adata, basis=\"spatial_cropped_150_buffer\", mpp=mpp)\n",
    "he_seg_out = output_dir / \"he.npz\"\n",
    "b2c.view_stardist_labels(\n",
    "    adata,\n",
    "    labels_npz_path=str(he_seg_out),\n",
    "    crop=crop,\n",
    "    labels_key=\"labels_he_expanded\",\n",
    "    save=output_dir / \"stardist_labels_he.png\"\n",
    ")\n",
    "print(\"View of H&E exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(b2c.bin2cell)\n",
    "grid_image_sigma = 5\n",
    "# 1. Generate GEX grid image and export\n",
    "gex_img_out = output_dir / \"gex.tiff\"\n",
    "img = b2c.grid_image(adata, \"n_counts_adjusted\", mpp=mpp, sigma=grid_image_sigma)\n",
    "cv2.imwrite(str(gex_img_out), img)\n",
    "print(f\"Exported GEX image to: {gex_img_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Run Stardist on the GEX TIFF\n",
    "gex_seg_out = output_dir / \"gex.npz\"\n",
    "b2c.stardist(\n",
    "    image_path=str(gex_img_out),\n",
    "    labels_npz_path=str(gex_seg_out),\n",
    "    **gex_stardist_params\n",
    ")\n",
    "print(\"Stardist GEX done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Insert GEX labels into adata\n",
    "b2c.insert_labels(\n",
    "    adata,\n",
    "    labels_npz_path=str(gex_seg_out),\n",
    "    basis=\"spatial\",  # or \"array\" if you prefer\n",
    "    spatial_key=\"spatial_cropped_150_buffer\",\n",
    "    mpp=mpp,\n",
    "    labels_key=\"labels_gex\"\n",
    ")\n",
    "print(\"Inserted GEX labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. GEX segmentation overlay (label visualization)\n",
    "bdata = adata[mask].copy()\n",
    "bdata = bdata[bdata.obs[\"labels_gex\"] > 0]\n",
    "bdata.obs[\"labels_gex\"] = bdata.obs[\"labels_gex\"].astype(str)\n",
    "\n",
    "sc.pl.spatial(\n",
    "    bdata,\n",
    "    color=[None, \"labels_gex\"],\n",
    "    img_key=f\"{mpp}_mpp_150_buffer\",\n",
    "    basis=\"spatial_cropped_150_buffer\",\n",
    "    show=False\n",
    ")\n",
    "plt.savefig(output_dir / \"gex_segmentation_labels_gex_overlay.png\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "print(\"Exported GEX segmentation label overlay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Normalized GEX overlay image\n",
    "crop = b2c.get_crop(bdata, basis=\"spatial\", mpp=mpp)\n",
    "rendered = b2c.view_labels(\n",
    "    image_path=gex_img_out,\n",
    "    labels_npz_path=gex_seg_out,\n",
    "    crop=crop,\n",
    "    stardist_normalize=True\n",
    ")\n",
    "plt.imshow(rendered)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"gex_segmentation_overlay_normalized.png\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "print(\"Exported normalized GEX overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Merge H&E and GEX labels\n",
    "b2c.salvage_secondary_labels(\n",
    "    adata,\n",
    "    primary_label=\"labels_he_expanded\",\n",
    "    secondary_label=\"labels_gex\",\n",
    "    labels_key=\"labels_joint\"\n",
    ")\n",
    "print(\"Salvaged H&E + GEX labels into labels_joint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Plot joint labels\n",
    "bdata = adata[mask].copy()\n",
    "bdata = bdata[bdata.obs[\"labels_joint\"] > 0]\n",
    "bdata.obs[\"labels_joint\"] = bdata.obs[\"labels_joint\"].astype(str)\n",
    "\n",
    "sc.pl.spatial(\n",
    "    bdata,\n",
    "    color=[None, \"labels_joint_source\", \"labels_joint\"],\n",
    "    img_key=f\"{mpp}_mpp_150_buffer\",\n",
    "    basis=\"spatial_cropped_150_buffer\",\n",
    "    show=False\n",
    ")\n",
    "plt.savefig(output_dir / \"labels_joint_overlay.png\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "print(\"Exported joint label overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Convert bins to cells\n",
    "cdata = b2c.bin_to_cell(\n",
    "    adata,\n",
    "    labels_key=\"labels_joint\",\n",
    "    spatial_keys=[\"spatial\", \"spatial_cropped_150_buffer\"]\n",
    ")\n",
    "sc.pl.spatial(\n",
    "    cdata,\n",
    "    color=[\"bin_count\"],\n",
    "    basis=\"spatial_cropped_150_buffer\",\n",
    "    img_key=f\"{mpp}_mpp_150_buffer\",\n",
    "    show=False\n",
    ")\n",
    "plt.savefig(output_dir / \"spatial_cell_density.pdf\")\n",
    "plt.close()\n",
    "print(\"Exported spatial cell density plot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export statistics\n",
    "stats = {\n",
    "    \"num_bins\": adata.shape[0],\n",
    "    \"num_genes\": adata.shape[1],\n",
    "    \"total_umis\": np.sum(adata.X),\n",
    "    \"avg_umis_per_bin\": np.mean(adata.X.sum(axis=1)),\n",
    "    \"num_cells\": len(np.unique(adata.obs[\"labels_joint\"])),\n",
    "    \"avg_bin_per_cell\": adata.shape[0] / len(np.unique(adata.obs[\"labels_joint\"]))\n",
    "}\n",
    "\n",
    "stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin2cell_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
